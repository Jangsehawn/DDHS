{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yM6YZkUE8FhZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.neighbors import KernelDensity\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# autoencoder\n",
        "class Autoencoder(nn.Module):\n",
        "  def __init__(self, input_dim, latent_dim):\n",
        "      super().__init__()\n",
        "      self.encoder = nn.Sequential(\n",
        "           nn.Linear(input_dim, 256),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(256, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, latent_dim)\n",
        "        )\n",
        "      self.decoder = nn.Sequential(\n",
        "          nn.Linear(latent_dim, 128),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(128, 256),\n",
        "          nn.ReLU(),            \n",
        "          nn.Linear(256, input_dim)\n",
        "        )\n",
        "      self.centers = nn.Parameter(torch.randn(2, latent_dim))\n",
        "    \n",
        "  def forward(self, x):\n",
        "      encoded = self.encoder(x)\n",
        "      decoded = self.decoder(encoded)        \n",
        "      return encoded, decoded\n",
        "    \n",
        "  def get_center_loss(self, encoded, target):\n",
        "      batch_size = encoded.size(0)\n",
        "      target = target.reshape(-1, 1) #   view\n",
        "      centers_batch = self.centers.gather(0, target.to(torch.int64).repeat(1, encoded.size(1))) \n",
        "      center_loss = (encoded - centers_batch).pow(2).sum() / batch_size\n",
        "      return center_loss\n",
        "  \n",
        "\n",
        "\n",
        "# imbalanced에 data level로 해결하는 모델\n",
        "class DDHS:\n",
        "  #데이터를 KDE로 가우시안 분포를 이용하여 중간 %를 추출하는 함수\n",
        "  # start, last에 퍼센트를 입력\n",
        "\n",
        "  def extract_middle_percent(self,data, start, last):\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "\n",
        "    # kde가 큰 데이터셋에서 오래 걸려서서 percentile로 간소화\n",
        "    if len(data_scaled) > 10000 : \n",
        "      threshold_low, threshold_high = np.percentile(data_scaled, [start, last])\n",
        "      mask = np.logical_and(data_scaled >= threshold_low, data_scaled <= threshold_high)\n",
        "      mask = [True if i.sum() > len(i)/2 else False for i in mask]  \n",
        "    else:\n",
        "      kde = KernelDensity(kernel='gaussian', bandwidth=0.5).fit(data_scaled)\n",
        "      log_prob = kde.score_samples(data_scaled)\n",
        "      prob = np.exp(log_prob)\n",
        "      threshold_low, threshold_high = np.percentile(prob, [start, last])\n",
        "      mask = np.logical_and(prob >= threshold_low, prob <= threshold_high) #######\n",
        "    \n",
        "    data_middle = data[mask]\n",
        "\n",
        "    if len(data_middle) > 0 :\n",
        "      return data_middle\n",
        "    else:  \n",
        "      print(\"No middle 50% found, returning original data\")\n",
        "      return np.array([])\n",
        "\n",
        "  #  각 feature 안의 값을 복원추출하는 함수\n",
        "\n",
        "  def reconstruct_features(self,data):\n",
        "    mean = data.mean(axis=0)\n",
        "    std = data.std(axis=0)\n",
        "    reconstructed = np.random.randn(*data.shape) * std + mean\n",
        "    return reconstructed\n",
        "\n",
        "  # synthetic sample을 생성하는 함수\n",
        "  # 라벨과과 데이터를 하나의 데이터프레임으로 출력\n",
        "  # small class / large class의 비율 = ratio \n",
        "\n",
        "\n",
        "  def generate_synthetic_sample(self,X,Y, ratio=1):\n",
        "\n",
        "    data = pd.concat([X,Y],axis=1)\n",
        "\n",
        "    # small class\n",
        "    data_A = data[data[Y.columns[0]]== Y.value_counts().idxmin()[0]  ].loc[:, data.columns != Y.columns[0]].astype(float).values\n",
        "\n",
        "    # large class \n",
        "    data_B = data[data[Y.columns[0]]== Y.value_counts().idxmax()[0] ].loc[:, data.columns != Y.columns[0]].astype(float).values\n",
        "\n",
        "    # autoencoder를 사용하여 잠재 변수를 추출\n",
        "    with torch.no_grad():\n",
        "        encoded_A, _ = self.model(torch.tensor(data_A).float())\n",
        "        encoded_B, _ = self.model(torch.tensor(data_B).float())\n",
        "  \n",
        "    # Majority : 입력받은 퍼센트 보다 Density가 큰 샘플을 Keep→ 입력받은 퍼센트 샘플을 Classifier 의 Train 데이터로 활용\n",
        "    # Minority : 입력받은 퍼센트 을 사용해서 더 높은 기준을 설정 → 입력받은 퍼센트 샘플을 Classifier 의 Train 데이터로 활용 → 25% 샘플을 Subsequence 생성 과정의 샘플로 활용\n",
        "  \n",
        "    encoded_A_middle = self.extract_middle_percent(encoded_A.cpu().numpy(),50 - self.small_percent/2 , 50+ self.small_percent/2) \n",
        "    encoded_B_middle = self.extract_middle_percent(encoded_B.cpu().numpy(),50 -self.large_percent/2, 50 + self.large_percent/2)\n",
        "\n",
        "    # 중간 25%의 잠재 변수로부터 feature를 복원추출 \n",
        "    reconstructed_features = self.reconstruct_features(self.extract_middle_percent(encoded_A.cpu().numpy(),37.5, 62.5))\n",
        "    # 임의의 위치에 synthetic sample 생성\n",
        "    center_A = np.mean(encoded_A.cpu().numpy(), axis=0, dtype=np.float64, out=None)\n",
        "\n",
        "    center_B = np.mean(encoded_B.numpy(), axis=0, dtype=np.float64, out=None) \n",
        "\n",
        "    radius_A = np.max(np.linalg.norm(encoded_A.cpu().numpy() - center_A, axis=1))\n",
        "\n",
        "    synthetic_sample = pd.DataFrame() # 최종 합치기\n",
        "   \n",
        "   # 합성된 개수 / 원래 클래스 개수\n",
        "    while len(synthetic_sample)/len(data_A) >= ratio :\n",
        "        z = np.random.randn(latent_dim)\n",
        "        if np.linalg.norm(z - center_A) < np.linalg.norm(z - center_B) and np.linalg.norm(z - center_A) < radius_A:\n",
        "            synthetic_sample.append(z) #, ignore_index=True)\n",
        "\n",
        "    # 최종 출력할 데이터 \n",
        "    encoded_B_middle = pd.DataFrame(encoded_B_middle)\n",
        "    encoded_B_middle['label'] = Y.value_counts().idxmax()[0]\n",
        "\n",
        "    encoded_A_middle = pd.DataFrame(encoded_A_middle)\n",
        "    encoded_A_middle['label'] = Y.value_counts().idxmin()[0] \n",
        "\n",
        "    synthetic_sample['label'] = Y.value_counts().idxmin()[0] \n",
        "\n",
        "    ouput = pd.concat([encoded_B_middle,encoded_A_middle,synthetic_sample ] )\n",
        "\n",
        "    x_ = ouput.loc[:, ouput.columns != 'label']\n",
        "    x_.columns = X.columns\n",
        "    y_ = ouput['label']\n",
        "    y_.columns = Y.columns\n",
        "\n",
        "    return x_ , y_\n",
        "\n",
        "  def fit(self,X,Y,large_percent = 50 , small_percent = 75 ,lr = 1e-3 ,num_epochs = 50, ratio = 1):\n",
        "    self.ratio = ratio\n",
        "    self.large_percent = large_percent\n",
        "    self.small_percent = small_percent\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    input_dim = len(X.columns) # 데이터의 차원\n",
        "    latent_dim = len(X.columns) # 잠재 변수의 차원\n",
        "    #ratio =  합성된 데이터 수/small class  비율\n",
        "    #large_percent : large class의 추출 비율\n",
        "    #small_percent : small class의 추출 비율 \n",
        "    #lr = 1e-3 # 학습률\n",
        "    #num_epochs = 50 # 학습 에폭 수\n",
        "    \n",
        "    self.model = Autoencoder(input_dim, latent_dim).to(device)\n",
        "    optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      x = torch.tensor(X.to_numpy()).float()#.to(device)\n",
        "      y = torch.tensor(Y[Y.columns[0]].to_numpy()).float().to(device)\n",
        "\n",
        "      encoded, decoded = self.model(x)\n",
        "      reconstruction_loss = F.mse_loss(decoded, x)\n",
        "      center_loss = self.model.get_center_loss(encoded, y)\n",
        "\n",
        "      loss = reconstruction_loss + center_loss\n",
        "      cross_entropy_loss = F.cross_entropy(decoded, y.long()) # y를 long 형으로 요구\n",
        "      loss += cross_entropy_loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    \n",
        "    synthetic_X, synthetic_Y = self.generate_synthetic_sample(X,Y, self.ratio)\n",
        "    return synthetic_X, synthetic_Y\n",
        "\n",
        "\n",
        "  def __init__(self):\n",
        "    self.result = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "magic = pd.read_csv('/content/drive/MyDrive/DDHS/magic04.data')"
      ],
      "metadata": {
        "id": "7xwiruNeD-4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre(x):\n",
        "  if x =='g':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "magic['g']=magic['g'].apply(pre)"
      ],
      "metadata": {
        "id": "Bana4zq7D-8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "ddhs = DDHS()\n",
        "\n",
        "X,y = ddhs.fit(magic.drop('g',axis=1), magic[['g']],50,75,1e-3,100,1)"
      ],
      "metadata": {
        "id": "VMjIIcNbD--z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    shuffle=True, \n",
        "                                                    stratify=y,\n",
        "                                                    random_state=1004)"
      ],
      "metadata": {
        "id": "BUzMn1ioQaX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(num_leaves=31, objective='binary')\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "y_pred = lgb_clf.predict(X_val)"
      ],
      "metadata": {
        "id": "WvYdZqeMEqNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-5uqYxdEqLg",
        "outputId": "edc93fda-d842-4790-b786-2bcc5f6a13aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.85      0.89      1505\n",
            "           1       0.86      0.94      0.90      1538\n",
            "\n",
            "    accuracy                           0.90      3043\n",
            "   macro avg       0.90      0.90      0.90      3043\n",
            "weighted avg       0.90      0.90      0.90      3043\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y = magic.drop('g',axis=1), magic[['g']]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, \n",
        "                                                    y, \n",
        "                                                    test_size=0.3, \n",
        "                                                    shuffle=True, \n",
        "                                                    stratify=y,\n",
        "                                                    random_state=1004)\n",
        "lgb_clf = lgb.LGBMClassifier(num_leaves=31, objective='binary')\n",
        "lgb_clf.fit(X_train, y_train)\n",
        "y_pred = lgb_clf.predict(X_val)\n",
        "print(classification_report(y_val, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkN4dacvEp_j",
        "outputId": "b3e4dfc6-ac26-4efb-e243-9e67e12ff29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.82      2007\n",
            "           1       0.88      0.94      0.91      3699\n",
            "\n",
            "    accuracy                           0.88      5706\n",
            "   macro avg       0.88      0.85      0.86      5706\n",
            "weighted avg       0.88      0.88      0.88      5706\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm9__iynSVcT",
        "outputId": "8d77356c-a8d0-4e49-d8a3-5bee0877f204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "g\n",
              "1    12331\n",
              "0     6688\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6Cqq9S-aSVgh",
        "outputId": "d14845bf-1200-4d7d-e39c-69278b60a6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        28.7967   16.0021  2.6449  0.3918  0.1982   27.7004    22.011  \\\n",
              "0       31.6036   11.7235  2.5185  0.5303  0.3773   26.2722   23.8238   \n",
              "1      162.0520  136.0310  4.0612  0.0374  0.0187  116.7410  -64.8580   \n",
              "2       23.8172    9.5728  2.3385  0.6147  0.3922   27.2107   -6.4633   \n",
              "3       75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277   28.5525   \n",
              "4       51.6240   21.1502  2.9085  0.2420  0.1340   50.8761   43.1887   \n",
              "...         ...       ...     ...     ...     ...       ...       ...   \n",
              "19014   21.3846   10.9170  2.6161  0.5857  0.3934   15.2618   11.5245   \n",
              "19015   28.9452    6.7020  2.2672  0.5351  0.2784   37.0816   13.1853   \n",
              "19016   75.4455   47.5305  3.4483  0.1417  0.0549   -9.3561   41.0562   \n",
              "19017  120.5135   76.9018  3.9939  0.0944  0.0683    5.8043  -93.5224   \n",
              "19018  187.1814   53.0014  3.2093  0.2876  0.1539 -167.3125 -168.4558   \n",
              "\n",
              "       -8.2027   40.092   81.8828  \n",
              "0      -9.9574   6.3609  205.2610  \n",
              "1     -45.2160  76.9600  256.7880  \n",
              "2      -7.1513  10.4490  116.7370  \n",
              "3      21.8393   4.6480  356.4620  \n",
              "4       9.8145   3.6130  238.0980  \n",
              "...        ...      ...       ...  \n",
              "19014   2.8766   2.4229  106.8258  \n",
              "19015  -2.9632  86.7975  247.4560  \n",
              "19016  -9.4662  30.2987  256.5166  \n",
              "19017 -63.8389  84.6874  408.3166  \n",
              "19018  31.4755  52.7310  272.3174  \n",
              "\n",
              "[19019 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30a32c3a-2e5d-4334-9d38-2c3a017427c3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>28.7967</th>\n",
              "      <th>16.0021</th>\n",
              "      <th>2.6449</th>\n",
              "      <th>0.3918</th>\n",
              "      <th>0.1982</th>\n",
              "      <th>27.7004</th>\n",
              "      <th>22.011</th>\n",
              "      <th>-8.2027</th>\n",
              "      <th>40.092</th>\n",
              "      <th>81.8828</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31.6036</td>\n",
              "      <td>11.7235</td>\n",
              "      <td>2.5185</td>\n",
              "      <td>0.5303</td>\n",
              "      <td>0.3773</td>\n",
              "      <td>26.2722</td>\n",
              "      <td>23.8238</td>\n",
              "      <td>-9.9574</td>\n",
              "      <td>6.3609</td>\n",
              "      <td>205.2610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>162.0520</td>\n",
              "      <td>136.0310</td>\n",
              "      <td>4.0612</td>\n",
              "      <td>0.0374</td>\n",
              "      <td>0.0187</td>\n",
              "      <td>116.7410</td>\n",
              "      <td>-64.8580</td>\n",
              "      <td>-45.2160</td>\n",
              "      <td>76.9600</td>\n",
              "      <td>256.7880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.8172</td>\n",
              "      <td>9.5728</td>\n",
              "      <td>2.3385</td>\n",
              "      <td>0.6147</td>\n",
              "      <td>0.3922</td>\n",
              "      <td>27.2107</td>\n",
              "      <td>-6.4633</td>\n",
              "      <td>-7.1513</td>\n",
              "      <td>10.4490</td>\n",
              "      <td>116.7370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>75.1362</td>\n",
              "      <td>30.9205</td>\n",
              "      <td>3.1611</td>\n",
              "      <td>0.3168</td>\n",
              "      <td>0.1832</td>\n",
              "      <td>-5.5277</td>\n",
              "      <td>28.5525</td>\n",
              "      <td>21.8393</td>\n",
              "      <td>4.6480</td>\n",
              "      <td>356.4620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>51.6240</td>\n",
              "      <td>21.1502</td>\n",
              "      <td>2.9085</td>\n",
              "      <td>0.2420</td>\n",
              "      <td>0.1340</td>\n",
              "      <td>50.8761</td>\n",
              "      <td>43.1887</td>\n",
              "      <td>9.8145</td>\n",
              "      <td>3.6130</td>\n",
              "      <td>238.0980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19014</th>\n",
              "      <td>21.3846</td>\n",
              "      <td>10.9170</td>\n",
              "      <td>2.6161</td>\n",
              "      <td>0.5857</td>\n",
              "      <td>0.3934</td>\n",
              "      <td>15.2618</td>\n",
              "      <td>11.5245</td>\n",
              "      <td>2.8766</td>\n",
              "      <td>2.4229</td>\n",
              "      <td>106.8258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19015</th>\n",
              "      <td>28.9452</td>\n",
              "      <td>6.7020</td>\n",
              "      <td>2.2672</td>\n",
              "      <td>0.5351</td>\n",
              "      <td>0.2784</td>\n",
              "      <td>37.0816</td>\n",
              "      <td>13.1853</td>\n",
              "      <td>-2.9632</td>\n",
              "      <td>86.7975</td>\n",
              "      <td>247.4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19016</th>\n",
              "      <td>75.4455</td>\n",
              "      <td>47.5305</td>\n",
              "      <td>3.4483</td>\n",
              "      <td>0.1417</td>\n",
              "      <td>0.0549</td>\n",
              "      <td>-9.3561</td>\n",
              "      <td>41.0562</td>\n",
              "      <td>-9.4662</td>\n",
              "      <td>30.2987</td>\n",
              "      <td>256.5166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19017</th>\n",
              "      <td>120.5135</td>\n",
              "      <td>76.9018</td>\n",
              "      <td>3.9939</td>\n",
              "      <td>0.0944</td>\n",
              "      <td>0.0683</td>\n",
              "      <td>5.8043</td>\n",
              "      <td>-93.5224</td>\n",
              "      <td>-63.8389</td>\n",
              "      <td>84.6874</td>\n",
              "      <td>408.3166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19018</th>\n",
              "      <td>187.1814</td>\n",
              "      <td>53.0014</td>\n",
              "      <td>3.2093</td>\n",
              "      <td>0.2876</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>-167.3125</td>\n",
              "      <td>-168.4558</td>\n",
              "      <td>31.4755</td>\n",
              "      <td>52.7310</td>\n",
              "      <td>272.3174</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19019 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30a32c3a-2e5d-4334-9d38-2c3a017427c3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30a32c3a-2e5d-4334-9d38-2c3a017427c3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30a32c3a-2e5d-4334-9d38-2c3a017427c3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}